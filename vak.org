* Meetings
** <2025-02-07 Fri> overleg AF
- word boundaries te bespreken
- common crawl : filter op periode is voor de crawling tijdens deze periode.  de informatie die hiermee wordt gevonden kan al veel ouder zijn.   enerzijds is dat een probleem.  anderszijds willen we ons ook niet beperken tot enkel nieuwe informatie tijdens deze periode gepubliceerd.  enkele nieuwe info is allicht relevanter voor social media.
- evaluatie criteratie relevant
- evaluatie criteria disinformatie
- bekijken welke data nu juist mee te nemen voor disinformatie?   lijst van URLs?
- feedback VAF : research questions beperken en groeperen.  andere zaken?
- TikTok API : test gedaan, technische verbinding is OK.
- EuroHPC : reminder gestuurd, spam folder student.ou.nl account?
 => Servicedesk, ITF <servicedesk@ou.nl>

AF :
introductie meer uitgebreid
related literature ook meer uitgebreid
ofwel per onderzoeksvraag 1 hoofdstuk
ofwel datapreparatie 1 hoofdstuk, dan model, ...

scenarios 

beslissingen in AF opsommen

https://guides.lib.uni.edu/media-accuracy-media-bia-media-trends/logical-fallacies

filtering, evaluation, ..
perhaps limit to one specific source of migrants.

rumour detection 1 class classification te bekijken?


** <2025-02-28 Fri> overleg AF

points to discuss :

- tiktok status update and further steps. See excel sheet for a (subset of the) list of videos filtered on the keywords we determined.  Volume increases in time. Descriptions are often incoherent, voice2text almost always empty.  Quality?  Keywords revision necessary?
=> additional keywords 2 step strategy : candidate set en dan bijkomende filtering.  ukrain / russia.
=> whisper to transcribe 
=> between 30s and 2m, or 1m maximum
=> comments pas nadien na de filtering.
=> idem voor reddit.
Ukraine, Russia, Syria, Israel, Palestine
 
or Ukraine and Russia
 
- euroHPC status update.  I have a time budget of 800 node hours.   one node = 4 A100 GPUs.  This budget is allocated pro rata per month, no transfer possible.  Took some time to get this going + to find some way to actually keep 4 GPUs busy.
=> in begin process on one GPU.
=> huggingface.
- dataset update :
  - did extensive work to further limit the candidates.  57.858 remain.  37.769 filtered as irrelevant (total_nr_hits < 3 OR link_percentage >= 70%).   leaves 20.089 candidates.
  - examined FAISS vector store.   difficulty : we still need to know how to query the remaining candidates. also : English bias.
  -https://github.com/wietsedv/bertje 
  https://huggingface.co/papluca/xlm-roberta-base-language-detection
papluca/xlm-roberta-base-language-detection · Hugging Face
We’re on a journey to advance and democratize artificial intelligence through open source and open science.
 
  - looked into keyword / topic extraction: chunkeyBert.  summarize in 5 keywords, my hope is to be able to easily spot relevant / irrelevant.  We can still use FAISS approach for estimate of disinformation.  difficulty : heavy bias towards english
  - => automatic translation from Dutch/French to English using Helsinki-NLP/opus-mt-*-en.  major rabbithole!  batch_size, sampling/no-sampling, hyperparameters of huggingface transformers, parallellism, ...

limit to 4000 tokens maximum

scope :
- tiktok : extract from whisper
- setup questions FAISS 512 words 2 - 3 questions
- first version of the database
- important to sample!.
- dan pas experiments

summary of our meeting of today 2025-02-28 :

tiktok and reddit.
 
- I have found an initial list of videos / reddit posts containing at least one hit for our initial list of keywords.  due to the number of hits, I will use a 2 step strategy to reduce that initial list even more.   This will be done by :
  - using additional keywords.  Candidate additional keywords lists are : 1. ukraine, russia or 2. ukraine, russia, syria, israel, palestine.
  - limiting tiktok videos to videos between 30s and 1-2 minutes.
- comments will only be downloaded and taken into account for the second stage video candidates
- text transcription can be done using whisper model on the second stage video candidates.


internet articles (news outlets and political parties)

- about 20.000 articles remain after extensive filtering (initial keywords) and delta calculations (only new URLs during timeframe taken into account)
- I have English translations + 5 keywords summary done by cunkeyBert for those 20.000 articles
- for each article, 2 judgements must be made: 1) is the article relevant for the research and 2) does it contain disinformation
- judging the relevance of the articles will be done by using the same 2 step approach as for tiktok,  meaning I will look for those keywords in the chunkeyBert keywords / summaries.  We will limit our articles to max 4000 words.  This will yield a second stage list of articles.
- judging whether an article from the second stage list of articles contains disinformation or not will be done by doing a semantic embedding of each article.  These embeddings will be stored in a vector store.  The vector store will be queried to retrieve documents that are highly likely to contain disinformation.   I will propose a list of possible queries for this.


scope for next meeting : 
- setup the questions to be used to interrogate the vector store.
- finalize as much as possible the news article database, 2 judgements done for all 20.000 articles.
- experiment with whisper for some videos 


Dear Clara and Stefano,

I have been looking at some of the most commonly used disinformation discourses.  I have found the following broad categories :


- economic disinformation narratives
- labor market-related narratives
- security-related narratives
- public health-related narratives
- cultural assimilation narratives
- "Great Replacement" or other conspiracy narratives
- nationalist and far-right narratives
- fairness-based narratives
- fear-driven narratives
- apocalyptic narratives

Therefore, to detect each kind of narrative, I would propose the following questions (to be used to semantically query a vector store) :

- economic: Do immigrants pose a financial burden on the welfare system?  Do immigrants drain public resources?
- labor market: Are immigrants taking jobs from citizens?
- security: Do immigrants increase crime rates?
- public health: Are immigrants linked to spreading diseases?
- cultural assimilation: Do immigrants refuse to integrate into society?  Do immigrants refuse to integrate into local culture?
- "Great Replacement" or other conspiracy: Are immigration policies leading to the replacement of native populations?  Is mass immigration a deliberate plot to replace native populations?
- nationalist and far-right: Is mass immigration a deliberate strategy to weaken national identity?  Does immigration undermine national identity?
- fairness: Are immigrants receiving preferential treatment over citizens?  Are immigrants given unfair preferential treatment?
- fear: Do open borders lead to uncontrolled waves of criminals and terrorists?  Do open borders attract criminals and terrorists?
- apocalyptic: Is immigration an existential threat to Western society?

  


3. **Is immigration an existential threat to our society?**  


potential questions :

Do immigrants pose a financial burden on the welfare system?
Targets economic disinformation narratives.

Are immigrants taking jobs from native-born citizens?
Addresses labor market-related misinformation.

Do immigrants increase crime rates in host countries?
Focuses on security-related disinformation.

Are immigrants linked to the spread of diseases?
Examines public health-related misinformation.

Do immigrants refuse to integrate into society?
Targets cultural assimilation myths.

Are immigration policies leading to the replacement of native populations?
Checks for "Great Replacement" conspiracy rhetoric.

Is mass immigration a deliberate strategy to weaken national identity?
Investigates nationalist and far-right narratives.

Are immigrants receiving preferential treatment over citizens?
Looks at fairness-based misinformation.

Do open borders lead to uncontrolled waves of criminals and terrorists?
Explores fear-driven disinformation.

Is immigration an existential threat to Western civilization?
Targets apocalyptic-style disinformation claims.


1. **Do immigrants drain public resources?**  
   *Targets economic disinformation.*  

2. **Are immigrants taking jobs from citizens?**  
   *Addresses labor market myths.*  

3. **Do immigrants increase crime rates?**  
   *Focuses on security narratives.*  

4. **Are immigrants linked to spreading diseases?**  
   *Covers public health fears.*  

5. **Do immigrants refuse to integrate into local culture?**  
   *Highlights cultural assimilation myths.*  

6. **Is mass immigration a deliberate plot to replace native populations?**  
   *Examines "Great Replacement" rhetoric.*  

7. **Does immigration undermine national identity?**  
   *Targets identity-based disinformation.*  

8. **Are immigrants given unfair preferential treatment over citizens?**  
   *Focuses on perceived inequity claims.*  

9. **Do open borders attract criminals and terrorists?**  
   *Explores security and border control fears.*  

10. **Is immigration an existential threat to our society?**  
   *Captures apocalyptic disinformation narratives.*


most commonly used disinformation discourses.
- **Economic Drain:** Immigrants are falsely portrayed as overburdening public resources.  
- **Job Theft:** Claims suggest immigrants take jobs from native citizens.  
- **Crime Increase:** Immigrants are often linked to higher crime rates without evidence.  
- **Disease Spread:** Narratives falsely associate immigrants with epidemics.  
- **Cultural Non-Integration:** Immigrants are depicted as unwilling to assimilate.  
- **Great Replacement:** Conspiracy claims argue immigrants are replacing native populations.  
- **National Identity Threat:** Immigrants are said to undermine traditional cultural values.  
- **Preferential Treatment:** False beliefs claim immigrants receive undue benefits.  
- **Security Risk:** Immigrants are accused of introducing terrorism or criminal elements.  
- **Existential Threat:** Immigration is portrayed as a danger to the very fabric of society.
* links

[[https://emschwartz.me/understanding-the-bm25-full-text-search-algorithm/][BM25 search algorithm]]
https://github.com/Florents-Tselai/WarcDB
https://github.com/iipc/jwarc
https://medium.com/@samuel.schaffhauser/using-the-common-crawl-as-a-data-source-693a41b3baa9
index lijst downloaden op https://medium.com/@samuel.schaffhauser/using-the-common-crawl-as-a-data-source-693a41b3baa9
https://pullpush.io
https://developers.tiktok.com/products/research-api/
https://sf16-va.tiktokcdn.com/obj/eden-va2/lapz_k4_rvarpa/ljhwZthlaukjlkulzlp/form/research-endorsement-letter.pdf
https://vast.ai/
https://www.shepbryan.com/blog/what-is-gguf

let op : er is EU disinfo lab en eu vs disinfo

https://www.disinfo.eu/publications/disinformation-landscape-in-the-netherlands/
https://www.disinfo.eu/publications/disinformation-landscape-in-belgium/

project dat in belgie socials checkte op disinformatie
https://crossover.social/

mee te nemen?
https://www.reddit.com/r/Antwerpen/


https://euvsdisinfo.eu/ukraine/

commonly used narratives :
https://edmo.eu/publications/disinformers-use-similar-arguments-and-techniques-to-steer-hate-against-migrants-from-ukraine-or-the-global-south-2/
https://benedmo.eu/
https://belux.edmo.eu
https://www.logicallyfacts.com/
https://www.migrationpolicy.org/article/disinformation-migration-how-fake-news-spreads
https://www.europarl.europa.eu/RegData/etudes/IDAN/2021/653641/EXPO_IDA(2021)653641_EN.pdf


https://crisiscentrum.be/nl/risicos-belgie/veiligheidsrisicos/desinformatie/desinformatie
->
https://www.mediawijs.be/nl
https://www.mediawijsheid.nl/nepnieuws/
https://www.watwat.be/fake-news/hoe-weet-ik-online-tekst-fotos-videos-echt-fake-zijn
https://www.isdatechtzo.nl/


EuroHPC support :
We can also be contacted by email at: servicedesk@lxp.lu
https://docs.lxp.lu/first-steps/handling_jobs/#viewing-jobs-in-the-queue

python scripts en modellen downloaden op voorhand :
https://docs.lxp.lu/howto/HFInference/

** tiktok
[[https://developers.tiktok.com/doc/vce-getting-started][dev account getting started]]
[[https://developers.tiktok.com/research/7467661064878098438][credentials dev account]]
[[https://developers.tiktok.com/doc/research-api-get-started][research api getting started]]
[[https://developers.tiktok.com/doc/client-access-token-management][generate an access token]]
[[https://developers.tiktok.com/doc/research-api-specs-query-videos?enter_method=left_navigation][API reference - query videos]]
[[https://developers.tiktok.com/doc/research-api-specs-query-video-comments?enter_method=left_navigation][API reference - query video comments]]

common crawl parquet

https://data.commoncrawl.org/cc-index/table/cc-main/index.html
https://commoncrawl.org/blog/index-to-warc-files-and-urls-in-columnar-format

keyword extraction : 

https://huggingface.co/Voicelab/vlt5-base-keywords
https://huggingface.co/google/mt5-large

automatic speech recognition :

https://huggingface.co/openai/whisper-large-v3-turbo

65 minuten:  
batch size = 1
            translated_ids = model.generate(
                **inputs,
                max_length=max_output_length,
                do_sample=False,
                num_beams=3,
                no_repeat_ngram_size=3,
                early_stopping=True,
                repetition_penalty=2.0,
                length_penalty=1.1,
                pad_token_id=tokenizer.pad_token_id
            )
geen herhalingen. betrekkelijk goede kwaliteit


* datasets

[[https://www.kaggle.com/code/akshayr009/fakenewsdetection]]
https://www.kaggle.com/datasets/corrieaar/disinformation-articles
https://www.kaggle.com/datasets/imuhammad/euvsdisinfo-disinformation-database


* Mails

Dear Clara and Stefano,

I was working with the tiktok research API and noticed this is a severely limited API.  

Some limitations :

- max 1000 calls per day, max 100.000 results per day
- even if you ask for the maximum of 100 videos in a call, you almost always get less than that (due to deleted videos, ...), meaning the amount of videos you can retrieve will be substantially less than 100.000
- you need to throttle your calls, one call every 10 seconds works, but not more than that.
- resuming the download of a specific day/query seems difficult as results are returned in descending video_id, but you are not allowed to specify that you want all videos with a video_id < previous_last_video_id
- no decent filtering in api on keywords is available, so you need to download everything and then filter
- you cannot use extented time periods and need to fetch this in pieces.
- you do not know how many results a query will return in total

Since I don't know how many videos are created per day and I can only do 1000 calls per day, this poses a problem.

I was wondering whether you have used this API yourself?  If you have, in particular I would be interested in knowing if you succeeded in resuming from a last succesful id?

There is also the VCE environment that should allow for batch submissions which I will look into.

In the meantime, looking at the fields we can use to filter (and thus restrict the number of possible videos), I think the region_code might be interesting.  From the docs :

"A two digit code for the country where the video creator registered their account"

Could we limit the region_code to Belgium + the Netherlands + Ukraine + ... ?  If you see other countries that we should put into this list, please let me know.
perhaps we can play with the video_length field as well.   From the docs :

"The duration of the video SHORT: <15s MID: 15 ~60s LONG: 1~5min EXTRA_LONG: >5min"

A priori I would rather keep all videos, also the short ones, but if needed, this could be used as a filter as well.

** <2025-02-12 Wed> 

Dear Clara and Stefano,

I have tested the VCE (batch environment) of TikTok Research API.  Unfortunately, this environment only allows to fetch aggregated data, i.e. you can ask for counts of videos but not for individual video ids.  Other aggregates like max/min date etc are allowed but this is not what we are searching for.  Furthermore, filtering on countries is not supported.

That leaves us with the online API. To restate the main limitations : 1.000 API calls per day / max 100.000 items per day.  Many API calls return only a fraction of the max 100 items permitted per call.

It took me 3 days worth of API calls to download just the video ids (not even the comments yet) for a single day (2022-02-01), filtering on countries NL and BE.   Given that we are talking about a time period of almost 2 years (2022-02-01 -> 2024-11-30) and a couple of months to actually do the work, this is not going to work.  Also, most of the text is going to be in the comments, because a) most descriptions of videos are either absent or just a list of hashtags and b) the voice2text content was only present in 5 out of 71.460 videos.

We need a more agressive filtering strategy.  We could do this by :

- limiting time period
- limiting countries to just one (NL or BE)
- limiting to videos containing (many) comments- ... ?


Limiting to one country does not seem like a good strategy.   Even if we assume this would cut the number of videos in half, that would still mean 1 + 1/2 day of downloading per day just for the videos.
We could consider limiting the time period to the start of the war (first couple of weeks / months), where probably the most buzz around the war and its consequences was generated.
Limiting to videos containing many comments might be interesting.  p10 percentiles tell me p50 = 1, p80 = 5 and p90 = 12.  Please note if we focus on large comment counts, these comments have to be downloaded and this will "cost" API calls as well.

We could go for a combination of the above or come up with other strategies.

The research API does not allow to download videos, but there are tools that are capable of downloading videos given an id. If this works out, we could perhaps try some automatic audio transcription.

Interested in hearing your thoughts on this.

