* Meetings
** <2025-02-07 Fri> overleg VAF
- word boundaries te bespreken
- common crawl : filter op periode is voor de crawling tijdens deze periode.  de informatie die hiermee wordt gevonden kan al veel ouder zijn.   enerzijds is dat een probleem.  anderszijds willen we ons ook niet beperken tot enkel nieuwe informatie tijdens deze periode gepubliceerd.  enkele nieuwe info is allicht relevanter voor social media.
- evaluatie criteratie relevant
- evaluatie criteria disinformatie
- bekijken welke data nu juist mee te nemen voor disinformatie?   lijst van URLs?
- feedback VAF : research questions beperken en groeperen.  andere zaken?
- TikTok API : test gedaan, technische verbinding is OK.
- EuroHPC : reminder gestuurd, spam folder student.ou.nl account?
 => Servicedesk, ITF <servicedesk@ou.nl>

AF :
introductie meer uitgebreid
related literature ook meer uitgebreid
ofwel per onderzoeksvraag 1 hoofdstuk
ofwel datapreparatie 1 hoofdstuk, dan model, ...

scenarios 

beslissingen in AF opsommen

https://guides.lib.uni.edu/media-accuracy-media-bia-media-trends/logical-fallacies

filtering, evaluation, ..
perhaps limit to one specific source of migrants.

rumour detection 1 class classification te bekijken?


* links

[[https://emschwartz.me/understanding-the-bm25-full-text-search-algorithm/][BM25 search algorithm]]
https://github.com/Florents-Tselai/WarcDB
https://github.com/iipc/jwarc
https://medium.com/@samuel.schaffhauser/using-the-common-crawl-as-a-data-source-693a41b3baa9
index lijst downloaden op https://medium.com/@samuel.schaffhauser/using-the-common-crawl-as-a-data-source-693a41b3baa9
https://pullpush.io
https://developers.tiktok.com/products/research-api/
https://sf16-va.tiktokcdn.com/obj/eden-va2/lapz_k4_rvarpa/ljhwZthlaukjlkulzlp/form/research-endorsement-letter.pdf
https://vast.ai/
https://www.shepbryan.com/blog/what-is-gguf

let op : er is EU disinfo lab en eu vs disinfo

https://www.disinfo.eu/publications/disinformation-landscape-in-the-netherlands/
https://www.disinfo.eu/publications/disinformation-landscape-in-belgium/

project dat in belgie socials checkte op disinformatie
https://crossover.social/

mee te nemen?
https://www.reddit.com/r/Antwerpen/


https://euvsdisinfo.eu/ukraine/

commonly used narratives :
https://edmo.eu/publications/disinformers-use-similar-arguments-and-techniques-to-steer-hate-against-migrants-from-ukraine-or-the-global-south-2/
https://benedmo.eu/
https://belux.edmo.eu
https://www.logicallyfacts.com/
https://www.migrationpolicy.org/article/disinformation-migration-how-fake-news-spreads
https://www.europarl.europa.eu/RegData/etudes/IDAN/2021/653641/EXPO_IDA(2021)653641_EN.pdf


https://crisiscentrum.be/nl/risicos-belgie/veiligheidsrisicos/desinformatie/desinformatie
->
https://www.mediawijs.be/nl
https://www.mediawijsheid.nl/nepnieuws/
https://www.watwat.be/fake-news/hoe-weet-ik-online-tekst-fotos-videos-echt-fake-zijn
https://www.isdatechtzo.nl/


EuroHPC support :
We can also be contacted by email at: servicedesk@lxp.lu

** tiktok
[[https://developers.tiktok.com/doc/vce-getting-started][dev account getting started]]
[[https://developers.tiktok.com/research/7467661064878098438][credentials dev account]]
[[https://developers.tiktok.com/doc/research-api-get-started][research api getting started]]
[[https://developers.tiktok.com/doc/client-access-token-management][generate an access token]]
[[https://developers.tiktok.com/doc/research-api-specs-query-videos?enter_method=left_navigation][API reference - query videos]]
[[https://developers.tiktok.com/doc/research-api-specs-query-video-comments?enter_method=left_navigation][API reference - query video comments]]

* datasets

[[https://www.kaggle.com/code/akshayr009/fakenewsdetection]]
https://www.kaggle.com/datasets/corrieaar/disinformation-articles
https://www.kaggle.com/datasets/imuhammad/euvsdisinfo-disinformation-database


* Mails

Dear Clara and Stefano,

I was working with the tiktok research API and noticed this is a severely limited API.  

Some limitations :

- max 1000 calls per day, max 100.000 results per day
- even if you ask for the maximum of 100 videos in a call, you almost always get less than that (due to deleted videos, ...), meaning the amount of videos you can retrieve will be substantially less than 100.000
- you need to throttle your calls, one call every 10 seconds works, but not more than that.
- resuming the download of a specific day/query seems difficult as results are returned in descending video_id, but you are not allowed to specify that you want all videos with a video_id < previous_last_video_id
- no decent filtering in api on keywords is available, so you need to download everything and then filter
- you cannot use extented time periods and need to fetch this in pieces.
- you do not know how many results a query will return in total

Since I don't know how many videos are created per day and I can only do 1000 calls per day, this poses a problem.

I was wondering whether you have used this API yourself?  If you have, in particular I would be interested in knowing if you succeeded in resuming from a last succesful id?

There is also the VCE environment that should allow for batch submissions which I will look into.

In the meantime, looking at the fields we can use to filter (and thus restrict the number of possible videos), I think the region_code might be interesting.  From the docs :

"A two digit code for the country where the video creator registered their account"

Could we limit the region_code to Belgium + the Netherlands + Ukraine + ... ?  If you see other countries that we should put into this list, please let me know.
perhaps we can play with the video_length field as well.   From the docs :

"The duration of the video SHORT: <15s MID: 15 ~60s LONG: 1~5min EXTRA_LONG: >5min"

A priori I would rather keep all videos, also the short ones, but if needed, this could be used as a filter as well.
